<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Akshat Gupta</title>
  
  <meta name="author" content="Akshat Gupta">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
	<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üåê</text></svg>">
  <script type="text/javascript" src="script.js"></script>
</head>

<br><br>
<body onload="startGame()">
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Akshat Gupta</name>
              </p>
              <p>
                I am a second year CS PhD student at UC Berkeley affiliated with <a href="https://bair.berkeley.edu">BAIR</a> and Berkeley Speech Group, advised by Prof. <a href="http://people.eecs.berkeley.edu/~gopala/">Gopala Anumanchipalli</a>. 
                Before joining Berkeley, I spent two wonderful years at <a href="https://www.jpmorgan.com/technology/artificial-intelligence">AI Research, JPMorgan</a> where I worked as an NLP Research Engineer. 
                <br><br>
                I graduated from Carnegie Mellon University (MS), where I was advised by Prof. <a href="http://festvox.org/awb/">Alan Black</a>. 
                In another life, I used to study physics. I did my Masters in Physics from Technical University of Munich, Germany, and my thesis was advised by Prof. <a href="https://www.ams.jhu.edu/~eyink/">Gregory Eyink</a> at Johns Hopkins University.
                <br><br>
                Currently I am actively working on and constantly thinking about the following topics:
                <ul>
                    <li>Knowledge Editing and Memorization (<a href="https://arxiv.org/abs/2401.07453">1</a>, <a href="https://arxiv.org/abs/2403.07175">2</a>, <a href="https://arxiv.org/abs/2403.14236">3</a>, <a href="https://arxiv.org/abs/2405.00664">4</a>)</li></li>
                    <li>LLMs and Poker (<a href="https://arxiv.org/abs/2308.12466">1</a>, <b>PokerBench</b> out soon)</li>
                    <li>Generative Spoken Language Modelling (<a href="https://arxiv.org/abs/2410.07168">1</a>)</li>
                    <li>Personality Measurement in LLMs (<a href="https://arxiv.org/abs/2309.08163">1</a>, <a href="https://arxiv.org/abs/2305.14693">2</a>, <a href="https://arxiv.org/abs/2402.14805">3</a>)</li>
                    <!--<li>Personality Measurement in LLMs (<a href="https://arxiv.org/abs/2309.08163">1</a>, <a href="https://arxiv.org/abs/2305.14693">2</a>, <a href="https://arxiv.org/abs/2402.14805">3</a>)</li>-->
                </ul>
                <br>
                Please reach out if you're interested in these topics and want to chat.
                <!--<b>Note for Students and Potential Collaborators</b> : I love collaborations and have <a href="https://scalable-model-editing.github.io/team.html">mentored many students</a> on different research projects in the past. Please feel free to reach out to me to discuss ideas, my previous or current projects or collaborations.-->
              </p>
              <p style="text-align:center">
                <a href="mailto:akshat.gupta@berkeley.edu">Email</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?hl=en&user=v80j6o0AAAAJ">Google Scholar</a> &nbsp/&nbsp
                <a href="https://x.com/akshatgupta57">Twitter</a> &nbsp/&nbsp
                <a href="https://www.linkedin.com/in/akshat57/">Linkedin</a> &nbsp/&nbsp
                <a href="./data/CV_Akshat.pdf" target="_blank">CV</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/profile_akshat_circle.png"><img style="width:100%;max-width:100%" alt="profile photo" src="images/profile_akshat_circle.png" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        
        <section id="news">
          <h2 class="news-title">News</h2>
          <ul>
              <li>Dec 9, 2024 - "<b>PokerBench: Training LLMs to become Professional Poker Players</b>" accepted at <b>AAAI 2025</b>. Paper coming out soon.</li>
              <li>Nov 2024 - I will be attending EMNLP 2024 in Miami from November 11 - 16. Please reach out if you want to chat.  </li>
              <li>Sep 20, 2024 - <a href="https://arxiv.org/abs/2403.07175">"Rebuilding ROME : Resolving Model Collapse during Sequential Editing"</a> accepted to <b>EMNLP 2024 Main</b></li>
              <li>Sep 20, 2024 - <a href="https://arxiv.org/abs/2403.14236">"A Unified Framework for Model Editing"</a> accepted to <b>EMNLP 2024 Findings</b></li>
              <li>Sep 20, 2024 - <a href="https://arxiv.org/abs/2309.08163">"Self-Assessment Tests are Unreliable Measures of LLM Personality"</a> accepted to <b>BlackboxNLP 2024</b>, co-located with EMNLP 2024</li>
              <li>August 12, 2024 - Attending ACL 2024 in Bangkok!!</li>
              <li>May 15, 2024 - <a href="https://arxiv.org/abs/2401.07453">"Model Editing at Scale leads to Gradual and Catastrophic Forgetting"</a> accepted to <b>ACL 2024 Findings</b></li>
              <!--<<li>May 2, 2024 - <a href="https://arxiv.org/abs/2405.00664">"Is Bigger Edit Batch Size Always Better?- An Empirical Study on Model Editing with Llama-3"</a> picked by <a href="https://twitter.com/_akhaliq/status/1785869426924966190"> AK</a> as part of <a href="https://huggingface.co/papers/2405.00664"> Huggingface Daily Papers</a></li>-->
              <!--<li>March 21, 2024 - <a href="https://arxiv.org/abs/2403.14236">"A Unified Framework for Model Editing"</a> released on arxiv</li>
              <li>March 11, 2024 - <a href="https://arxiv.org/abs/2403.07175">"Rebuilding ROME : Resolving Model Collapse during Sequential Model Editing"</a> released on arxiv</li>
              <li>January 15, 2024 - <a href="https://arxiv.org/abs/2401.07453">"Model Editing at Scale leads to Gradual and Catastrophic Forgetting"</a> released on arxiv</li>-->
          </ul>
      </section>
        
        
</body>

</html>
